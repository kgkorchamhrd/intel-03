# -*- coding: utf-8 -*-
"""인텔 주식예측.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PL1DXDdz2GQrfHI4DhfJszcQGkGU9Tsf
"""

!pip install finance-datareader
import FinanceDataReader as fdr
import numpy as np
import matplotlib.pyplot as plt
import pickle

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, SimpleRNN, GRU, LSTM, Dropout

# 삼성전자 주식 데이터
df = fdr.DataReader('005930', '2018-05-04', '2020-01-22')
dfx = df[['Open','High','Low','Volume', 'Close']]
dfx = MinMaxScaler(dfx)
dfy = dfx[['Close']]
dfx = dfx[['Open','High','Low','Volume']]
# 범위를 0 ~ 1 로 normalized
def MinMaxScaler(data):

  numerator = data - np.min(data, 0)
  denominator = np.max(data, 0) - np.min(data, 0)
  # 0으로 나누기 에러가 발생하지 않도록 매우 작은 값(1e-7)을 더해서 나눔
  return numerator / (denominator + 1e-7)

plt.plot(dfy)
plt.show()

x = dfx.values.tolist()
y = dfy.values.tolist()


window_size = 10
data_x = []
data_y = []
for i in range(len(y) - window_size):
  _x = x[i : i + window_size] # 다음 날 종가(i+windows_size)는 포함되지 않음
  _y = y[i + window_size]
  # 다음 날 종가
  data_x.append(_x)
  data_y.append(_y)

train_size = int(len(data_y) * 0.7)
val_size = int(len(data_y) * 0.2)
train_x = np.array(data_x[0 : train_size])
train_y = np.array(data_y[0 : train_size])
val_x = np.array(data_x[train_size:train_size+val_size])
val_y = np.array(data_y[train_size:train_size+val_size])
test_size = len(data_y) - train_size - val_size
test_x = np.array(data_x[train_size+val_size: len(data_x)])
test_y = np.array(data_y[train_size+val_size: len(data_y)])
print('훈련 데이터의 크기 :', train_x.shape, train_y.shape)
print('검증 데이터의 크기 :', val_x.shape, val_y.shape)
print('테스트 데이터의 크기 :', test_x.shape, test_y.shape)

#RNN

model_rnn = Sequential()
model_rnn.add(SimpleRNN(units=20, activation='tanh',
                        return_sequences=True, input_shape=(10, 4)))
model_rnn.add(Dropout(0.1))
model_rnn.add(SimpleRNN(units=20, activation='tanh'))
model_rnn.add(Dropout(0.1))
model_rnn.add(Dense(units=1))
model_rnn.compile(optimizer='adam', loss='mean_squared_error')
history_rnn = model_rnn.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=70, batch_size=30)

# GRU 모델
model_gru = Sequential()
model_gru.add(GRU(units=20, activation='tanh',
                  return_sequences=True, input_shape=(10, 4)))
model_gru.add(Dropout(0.1))
model_gru.add(GRU(units=20, activation='tanh'))
model_gru.add(Dropout(0.1))
model_gru.add(Dense(units=1))
model_gru.compile(optimizer='adam', loss='mean_squared_error')
history_gru = model_gru.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=70, batch_size=30)

# LSTM 모델
model_lstm = Sequential()
model_lstm.add(LSTM(units=20, activation='tanh',
                    return_sequences=True, input_shape=(10, 4)))
model_lstm.add(Dropout(0.1))
model_lstm.add(LSTM(units=20, activation='tanh'))
model_lstm.add(Dropout(0.1))
model_lstm.add(Dense(units=1))
model_lstm.compile(optimizer='adam', loss='mean_squared_error')
history_lstm = model_lstm.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=70, batch_size=30)

# 모델 출력

# 예측 값 얻기
rnn_predictions = model_rnn.predict(val_x)
gru_predictions = model_gru.predict(val_x)
lstm_predictions = model_lstm.predict(val_x)

# 실제 값 (val_y)과 예측 값 비교 차트 그리기
x = np.arange(len(val_y))

plt.figure(figsize=(10, 6))
plt.plot(x, val_y, label='Actual', color='black', marker='o')
plt.plot(x, rnn_predictions, label='RNN Predictions', color='blue', marker='x')
plt.plot(x, gru_predictions, label='GRU Predictions', color='green', marker='x')
plt.plot(x, lstm_predictions, label='LSTM Predictions', color='red', marker='x')

plt.title('Model Predictions vs Actual Values')
plt.xlabel('Sample Index')
plt.ylabel('Value')
plt.legend()
plt.grid(True)
plt.show()